{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to dos:\n",
    "- fam number into classification (not values but columns)\n",
    "- categorize the ages in 3-4 kategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dataset.head()\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset.plot(kind='box', subplots=True, layout=(2,7), sharex=False, sharey=False,figsize=[22,12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset.hist(figsize=[25,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f, ax = plt.subplots(4, 3,figsize=[22,12])\n",
    "sns.violinplot(x = 'Sex', y = 'Survived', data = dataset,ax = ax[0,0])\n",
    "sns.barplot(x = 'Pclass',y ='Survived',data = dataset,hue = 'Embarked',ax = ax[0,1])\n",
    "sns.distplot(dataset[dataset['Survived']==1]['Age'].dropna(),norm_hist = True,bins = np.arange(0,81,1),color = 'blue',\n",
    "            ax = ax[0,2])\n",
    "sns.distplot(dataset[dataset['Survived']==0]['Age'].dropna(),norm_hist = True,bins = np.arange(0,81,1), color = 'red',\n",
    "            ax = ax[0,2])\n",
    "sns.violinplot(x = 'Sex', y = 'Fare', data = dataset,ax = ax[1,0])\n",
    "sns.barplot(x ='Pclass', y = 'Fare',data = dataset , hue = 'Embarked', ax = ax[1,1])\n",
    "sns.distplot(dataset[dataset['Survived']==1]['Fare'].dropna(),bins = np.arange(0,580,10),color = 'blue',\n",
    "            ax = ax[1,2])\n",
    "sns.distplot(dataset[dataset['Survived']==0]['Fare'].dropna(),bins = np.arange(0,580,10),color = 'red',\n",
    "            ax = ax[1,2])\n",
    "sns.violinplot(x = 'Sex', y ='SibSp',data = dataset,ax = ax[2,0])\n",
    "sns.barplot(x= 'Pclass', y = 'SibSp', data = dataset, hue = 'Embarked', ax = ax[2,1])\n",
    "sns.regplot(x = 'Fare', y = 'Age', data = dataset, ax = ax[2,2])\n",
    "sns.violinplot(x = 'Sex', y = 'Parch', data = dataset, ax = ax[3,0])\n",
    "sns.barplot(x = 'Pclass', y = 'Parch', data = dataset, hue = 'Embarked', ax = ax[3,1])\n",
    "plt.close(12)\n",
    "plt.close(13)\n",
    "plt.close(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('C:/Users/gavam/Desktop/ml_BookLab/Titanic/titanic_data/train.csv')\n",
    "dataset1 = pd.read_csv('C:/Users/gavam/Desktop/ml_BookLab/Titanic/titanic_data/test.csv')\n",
    "dataset2 = pd.read_csv('C:/Users/gavam/Desktop/ml_BookLab/Titanic/titanic_data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('C:/Users/gavam/Desktop/ml_BookLab/Titanic/titanic_data/gender_submission.csv').values\n",
    "y_train = dataset[['Survived']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "imputer = imputer.fit(dataset[['SibSp','Parch','Age']])\n",
    "dataset[['SibSp','Parch','Age']] = imputer.transform(dataset[['SibSp','Parch','Age']])\n",
    "\n",
    "imputer = Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "imputer = imputer.fit(dataset1[['SibSp','Parch','Age']])\n",
    "dataset1[['SibSp','Parch','Age']] = imputer.transform(dataset1[['SibSp','Parch','Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''DATA PREPERATION-MANIPULATION'''\n",
    "dataset['Cabin'] = dataset['Cabin'].replace(regex={r'[^NaN]': 1})\n",
    "dataset1['Cabin'] = dataset1['Cabin'].replace(regex={r'[^NaN]': 1})\n",
    "\n",
    "dataset['Fam_num'] = dataset['SibSp'] + dataset['Parch']\n",
    "dataset1['Fam_num'] = dataset1['SibSp'] + dataset1['Parch']\n",
    "#print (dataset.values[:,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Fam_num'] = np.where(dataset['Fam_num'].between(0,1), 1, dataset['Fam_num'])\n",
    "dataset['Fam_num'] = np.where(dataset['Fam_num'].between(2,3), 2, dataset['Fam_num'])\n",
    "dataset['Fam_num'] = np.where(dataset['Fam_num'].between(4,5), 3, dataset['Fam_num'])\n",
    "dataset['Fam_num'] = np.where(dataset['Fam_num'].between(6,20), 4, dataset['Fam_num'])\n",
    "\n",
    "dataset1['Fam_num'] = np.where(dataset1['Fam_num'].between(0,1), 1, dataset1['Fam_num'])\n",
    "dataset1['Fam_num'] = np.where(dataset1['Fam_num'].between(2,3), 2, dataset1['Fam_num'])\n",
    "dataset1['Fam_num'] = np.where(dataset1['Fam_num'].between(4,5), 3, dataset1['Fam_num'])\n",
    "dataset1['Fam_num'] = np.where(dataset1['Fam_num'].between(6,20), 4, dataset1['Fam_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''AGE IN CATEGORIES'''\n",
    "dataset['Age'] = np.where(dataset['Age'].between(0,12), 1, dataset['Age'])\n",
    "dataset['Age'] = np.where(dataset['Age'].between(13,30), 2, dataset['Age'])\n",
    "dataset['Age'] = np.where(dataset['Age'].between(30,50), 3, dataset['Age'])\n",
    "dataset['Age'] = np.where(dataset['Age'].between(50,100), 4, dataset['Age'])\n",
    "\n",
    "\n",
    "dataset1['Age'] = np.where(dataset1['Age'].between(0,12), 1, dataset1['Age'])\n",
    "dataset1['Age'] = np.where(dataset1['Age'].between(13,30), 2, dataset1['Age'])\n",
    "dataset1['Age'] = np.where(dataset1['Age'].between(30,50), 3, dataset1['Age'])\n",
    "dataset1['Age'] = np.where(dataset1['Age'].between(50,100), 4, dataset1['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Pclass'], prefix='Pclass', drop_first=True)], axis=1)\n",
    "dataset1 = pd.concat([dataset1,pd.get_dummies(dataset1['Pclass'], prefix='Pclass', drop_first=True)], axis=1)\n",
    "dataset.drop(['Pclass'],axis=1, inplace=True)\n",
    "dataset1.drop(['Pclass'],axis=1, inplace=True)\n",
    "\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Age'], prefix='Age', drop_first=True)], axis=1)\n",
    "dataset1 = pd.concat([dataset1,pd.get_dummies(dataset1['Age'], prefix='Age', drop_first=True)], axis=1)\n",
    "dataset.drop(['Age'],axis=1, inplace=True)\n",
    "dataset1.drop(['Age'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATA PREPERATION-MANIPULATION'''\n",
    "values = {'Sex': 1, 'Cabin': 0}\n",
    "X_train = dataset.fillna(value=values)\n",
    "X_test = dataset1.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace(['female','male'],[0,1])\n",
    "X_test = X_test.replace(['female','male'],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train[['Sex', 'Cabin','Fam_num', 'Pclass_2', 'Pclass_3',\n",
    "       'Age_2.0', 'Age_3.0', 'Age_4.0']]\n",
    "X_test= X_test[['Sex', 'Cabin','Fam_num', 'Pclass_2', 'Pclass_3',\n",
    "       'Age_2.0', 'Age_3.0', 'Age_4.0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.count_nonzero(np.isnan(X_train))\n",
    "# performing standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, plot_importance \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=100,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "clf_et = ExtraTreesClassifier()\n",
    "clf_bc = BaggingClassifier()\n",
    "clf_ada = AdaBoostClassifier()\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_xg = XGBClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "clf_svm = SVC()\n",
    "#clf_regressor = LinearRegression()\n",
    "#trainnig the model\n",
    "#regressor.fit(X_train, y_train)\n",
    "#predicting the model on test data ste\n",
    "#y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers = ['RandomForest','ExtraTrees','Bagging','AdaBoost','DecisionTree','XGBoost','LogisticRegression','SVM']\n",
    "scores = []\n",
    "models = [clf_rf, clf_et, clf_bc, clf_ada, clf_dt, clf_xg, clf_lr, clf_svm]\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train, y_train, scoring = 'accuracy', cv = 10, n_jobs = -1).mean()\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to get rid of 7 + need to add one hot to the Cabin info\n",
    "#importing model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#maiing object\n",
    "regressor = LinearRegression()\n",
    "#trainnig the model\n",
    "mean_regression = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = i)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    #predicting the model on test data ste\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred = y_pred > 0.5\n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #print(cm)\n",
    "    #print(accuracy_score(y_pred, y_test))\n",
    "    mean_regression.append(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanscore = np.array(mean_regression).mean()\n",
    "Classifiers.append('Linear Regression')\n",
    "scores.append(meanscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = pd.DataFrame(scores, index = Classifiers, columns = ['score']).sort_values(by = 'score',\n",
    "             ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-ea05395e2154>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-67-ea05395e2154>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    XGBoost\t0.831618\u001b[0m\n\u001b[1;37m           \t       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\tscore\n",
    "XGBoost\t0.831618\n",
    "SVM\t0.820458\n",
    "Bagging\t0.814915\n",
    "DecisionTree\t0.813791\n",
    "AdaBoost\t0.809171\n",
    "RandomForest\t0.807061\n",
    "LogisticRegression\t0.805813\n",
    "ExtraTrees\t0.800357\n",
    "Linear Regression\t0.781650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = PCA(n_components = 2).fit_transform(X_train)\n",
    "X_test_reduced  = PCA(n_components =  2).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= dataset.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performng PCA \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 7)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "t = y_train.astype(np.integer)\n",
    "#clf_svm = SVC(**best_params_svm)\n",
    "#clf_svm.fit(X_train_reduced,t)\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train_reduced, t)\n",
    "y_pred = classifier.predict(X_test_reduced)\n",
    "plt.figure(figsize = [15,10])\n",
    "plot_decision_regions(X_train_reduced, t, clf = classifier, hide_spines = False, colors = 'purple,limegreen',\n",
    "                      markers = ['^','v'])\n",
    "plt.title('Support Vector Machines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance \n",
    "\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "#### VariableDefinitionKey: \n",
    "- survival Survival 0 = No, 1 = Yes pclass Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd \n",
    "- sex Sex Age Age in years sibsp # of siblings / spouses aboard the Titanic\n",
    "- parch # of parents / children aboard the Titanic ticket Ticket number fare Passenger fare cabin Cabin number \n",
    "- embarked Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "#### Variable Notes\n",
    "\n",
    "- pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "- age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "- sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "- parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "?str.replace()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what we need\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATA MANIPULATION (TRAIN)'''\n",
    "X1 = dataset.iloc[:,0]\n",
    "X2 = dataset.iloc[:, 2:]\n",
    "X = pd.concat([X1,X2], axis=1)\n",
    "X = X.replace(['female','male'],[0,1])#.values\n",
    "#y = y.replace(['NaN',],[0,1])\n",
    "X['Cabin'] = X['Cabin'].replace(regex={r'[^NaN]': 1})\n",
    "values = {'PassengerId': 'NoID', 'Pclass': X['Pclass'].mean(), 'Name': 'NoName', 'Sex': 1,\n",
    "          'Age': X['Pclass'].mean(),  'SibSp' : X['SibSp'].mean(), 'Parch' : X['Parch'].mean(),\n",
    "          'Ticket':'NoTicket', 'Fare':'NoFare', 'Cabin': 0, 'Embarked':'NoEmbarkedInfo' }\n",
    "X = X.fillna(value=values)\n",
    "X = X.round(1)\n",
    "X[['Pclass','Sex','Age','Pclass','SibSp','Cabin']] = X[['Pclass','Sex','Age','Pclass','SibSp','Cabin']].apply(np.int64)\n",
    "print ('The shape is',X.shape)\n",
    "X = X[['Pclass', 'Sex', 'Age', 'SibSp', 'Cabin']].values\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class vs Survived\n",
    "print(dataset[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sex vs Survived\n",
    "print(dataset[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SibSp vs Survived\n",
    "#Sibling = brother, sister, stepbrother, stepsister\n",
    "#Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "print(dataset[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parch vs Survived\n",
    "#Parent = mother, father\n",
    "#Child = daughter, son, stepdaughter, stepson\n",
    "#Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "print(dataset[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "X = np.append(np.ones((891,1)).astype(int),X,axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,1,2,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATA MANIPULATION (TRAIN)'''\n",
    "X_test = pd.read_csv('C:/Users/gavam/Desktop/ml_BookLab/Titanic/titanic_data/test.csv')\n",
    "X_test = X_test.replace(['female','male'],[0,1])\n",
    "X_test['Cabin'] = X_test['Cabin'].replace(regex={r'[^NaN]': 1})\n",
    "values = {'PassengerId': 'NoID', 'Pclass': X_test['Pclass'].mean(), 'Name': 'NoName', 'Sex': 1,\n",
    "          'Age': X_test['Pclass'].mean(),  'SibSp' : X_test['SibSp'].mean(), 'Parch' : X_test['Parch'].mean(),\n",
    "          'Ticket':'NoTicket', 'Fare':'NoFare', 'Cabin': 0, 'Embarked':'NoEmbarkedInfo' }\n",
    "X_test = X_test.fillna(value=values)\n",
    "X_test = X_test.round(1)\n",
    "X_test[['Sex','Age','Pclass','SibSp','Cabin']] = X_test[['Sex','Age','Pclass','SibSp','Cabin']].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['Pclass', 'Sex', 'Age', 'SibSp', 'Cabin']\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = X_test[['Pclass','Sex','Age','SibSp','Cabin']].values\n",
    "y_test = pd.read_csv('C:/Users/gavam/Desktop/ml_BookLab/Titanic/titanic_data/gender_submission.csv').values\n",
    "y_test = y_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    " \n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.min()\n",
    "y_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized Data\n",
    "normalized = np.array((y_pred-min(y_pred))/(max(y_pred)-min(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized[normalized > 0.5] = 1\n",
    "normalized[normalized <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(normalized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, normalized)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "classifier = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=1000,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
